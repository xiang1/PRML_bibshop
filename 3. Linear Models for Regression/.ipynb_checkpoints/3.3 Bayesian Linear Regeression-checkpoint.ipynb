{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Bayesian Linear Regression\n",
    "\n",
    "在前文的分析中，我们纯粹从数据出发，用最大似然方法能够得到数据模型的估计结果，后来为了限制模型的复杂度，我们添加了正则化项，模型的复杂度通常由**模型中基函数的个数**来决定，在模型求解中，可以通过训练数据的“hold-out”法则来确定模型的复杂度。\n",
    "\n",
    "#### 3.3.1 Paramerer distribution\n",
    "\n",
    "本节将从贝叶斯的角度去分析线性回归，介绍模型参数$\\mathbf{w}$的先验分布。\n",
    "\n",
    "1. 首先假设原始数据的噪声为0均值高斯分布，且方差$\\beta$已知。\n",
    "2. **似然函数** $p\\left(\\mathbf{t}| \\mathbf{w}\\right)$ 是二次函数的指数函数（也就是高斯函数），因此根据共轭先验的知识，我们假设$\\mathbf{w}$的**先验分布**为高斯分布：\n",
    "   \n",
    "   $$\n",
    "   p\\left(\\mathbf{w}\\right) =\\mathcal{N}\\left(\\mathbf{w}| \\mathbf{m_0}, \\mathbf{S_0}\\right)\n",
    "   $$\n",
    "  \n",
    "3. 那么进一步得到**后验概率分布**:  \n",
    "   \n",
    "   $$\n",
    "     p\\left(\\mathbf{w}| \\mathbf{t}\\right) =\\mathcal{N}\\left(\\mathbf{w}| \\mathbf{m_N}, \\mathbf{S_N}\\right)  \n",
    "   $$\n",
    "   \n",
    "   其中 $\\mathbf{m}_N = \\mathbf{S}_N\\left(\\mathbf{S}_0^{-1}\\mathbf{m}_0 + \\beta\\mathbf{\\Phi}^T \\mathbf{t}\\right)$, 且 $\\mathbf{S}_N^{-1} = \\mathbf{S}_0^{-1}+\\beta\\mathbf{\\Phi}^T \\mathbf{\\Phi}$\n",
    "   \n",
    "   \n",
    "当先验概率分布为0均值的高斯分布时，也即$\\mathbf{m_0} =0$， 我们可以进一步得到厚颜概率的对数结果为：\n",
    "\n",
    "$$\n",
    "\\ln p\\left(\\mathbf{w}| \\mathbf{t}\\right) = -\\frac{\\beta}{2}\\sum_{n=1}^N\\{t_n-\\mathbf{w}^T\\mathbf{\\phi\\left(\\mathbf{x_n}\\right)}\\}^2 - \\frac{\\alpha}{2}\\mathbf{w}^T\\mathbf{w} +const.\n",
    "$$\n",
    "\n",
    "上式中，最大化后验与前面的正则化项的方法等价，且$\\lambda = \\frac{\\alpha}{\\beta}$\n",
    "\n",
    "![贝叶斯的序列化学习](attachment:fig_3.7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Predictive distribution\n",
    "\n",
    "在实际应用中，我们更为关心的是预测结果 $\\mathbf{t}$ 而不是模型的参数$\\mathbf{w}$，这就需要我们去计算预测分布（后验概率），\n",
    "\n",
    "$$\n",
    "p\\left(t| \\mathbf{t}, \\mathbf{x}, \\alpha, \\beta \\right)  = \\int p\\left(t | \\mathbf{w},\\beta\\right)p\\left(w| \\mathbf{t}, \\alpha, \\beta\\right) dw\n",
    "$$\n",
    "\n",
    "其中$\\mathbf{t}$表示训练数据，且$\\int p\\left(t | \\mathbf{w},\\beta\\right)$表示似然，$p\\left(w| \\mathbf{t}, \\alpha, \\beta\\right)$ 表示先验。\n",
    "\n",
    "以两个高斯分布为例，我们得到后验分布为：\n",
    "\n",
    "$$\n",
    "p\\left(t| x,\\mathbf{t},  \\alpha, \\beta \\right) =\\mathcal{N}\\left(\\mathbf{m}_N^T \\phi\\left(x\\right), \\sigma_N^2\\left(x\\right)\\right)\n",
    "$$\n",
    "\n",
    "其中，分布的方差表示为：\n",
    "\n",
    "$$\n",
    "\\sigma_N^2\\left(x\\right) = \\frac{1}{\\beta} +\\mathbf{\\phi}\\left(x\\right)^T \\mathbf{S}_N\\mathbf{\\phi}\\left(x\\right)\n",
    "$$\n",
    "\n",
    "而$\\mathbf{S}_N^{-1} = \\mathbf{S}_0^{-1}+\\beta\\mathbf{\\Phi}^T \\mathbf{\\Phi}$依赖于训练数据，当训练数据的个数越多，那么$\\mathbf{\\phi}\\left(x\\right)^T \\mathbf{S}_N\\mathbf{\\phi}\\left(x\\right)$将越小，即 $\\sigma_N^2\\left(x\\right) \\leqslant \\sigma_{N+1}^2\\left(x\\right)$，这也就意味着，随着训练数据的增多，数据的\n",
    "预测越来越准确，目标变量的分布越来越集中。\n",
    "\n",
    "![预测结果的分布](attachment:fig_3.8.png)\n",
    "![模型的结果](attachment:fig_3.8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3 Equivalent Kernel\n",
    "\n",
    "通过前面的分析，根据训练数据，我们可以得到期望模型：\n",
    "\n",
    "$$\n",
    "y\\left(x, \\mathbf{m}_N\\right) = \\mathbf{m}_N^T\\mathbf{\\phi}\\left(x\\right) = \\beta\\mathbf{\\phi}\\left(x\\right)^T\\mathbf{S}_N \\mathbf{\\Phi}^T \\mathbf{t} = \\sum_{n=1}^N \\beta \\mathbf{\\phi}\\left(x\\right)^T \\mathbf{S}_N\\mathbf{\\phi}\\left(x_n\\right)t_n\n",
    "$$\n",
    "\n",
    "那么，我们可将上式转换为：\n",
    "\n",
    "$$\n",
    "y\\left(x, \\mathbf{m}_N\\right) =\\sum_{n=1}^N k\\left(x,x_n\\right)t_n\n",
    "$$\n",
    "\n",
    "其中 \n",
    "\n",
    "$$\n",
    "k\\left(x,x'\\right) = \\beta\\phi\\left(x\\right)^T\\mathbf{S}_N\\phi\\left(x'\\right)\n",
    "$$\n",
    "表示**等价核函数**或者称为**smoother matrix**\n",
    "\n",
    "因此，我们对于任何一个带有基函数的回归过程，等价于定义了一个类似的核函数的过程，其中核函数的定义可以遵从一下步骤：\n",
    "\n",
    "$$\n",
    " k\\left(x,z\\right) = \\psi\\left(x\\right)^T   \\psi\\left(z\\right)\n",
    "$$\n",
    "其中 $\\psi\\left(x\\right)= \\beta^{1/2}\\mathbf{S}_N^{1/2}\\phi\\left(x\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
