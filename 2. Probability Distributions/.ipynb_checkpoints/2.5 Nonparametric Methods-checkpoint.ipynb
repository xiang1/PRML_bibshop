{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Nonparameteric Methods\n",
    "\n",
    "前面我们用一些简单的直观的分布去近似，或者描述一堆数据，这称为**参数化方法**，然而有时候数据的真实分布是复杂而且并不直观，这时候我们需要用到**非参数方法**。\n",
    "\n",
    "下图中演示的是直方图方法，能够在一定程度上描述出数据的分布特征。\n",
    "\n",
    "![fig_2_24](2.5_fig_2_24.png)\n",
    "\n",
    "如上图所示，直方图方法描述原始数据特征具有如下的局限：\n",
    "* 1） 直方图方法中的曲线并不连续，他非常受限于直方图每个bin的划分；\n",
    "* 2） 直方图方法会出现数据爆炸的问题，因为当数据的维数增多时，我们需要来完整描述数据特征的数据的量呈指数增长。\n",
    "\n",
    "现在提供两种较好的非参数化方法： 1） Kernel density estimators; 2) Nearest-neighbour methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.1 Kernel density estimators\n",
    "\n",
    "现在我们考虑从未知分布 $p\\left(x\\right)$ 产生的N个数据，这个数据时$D$维的，从前面的分析我们，知道，这些数据位于区域$\\mathcal{R}$的概率表示为： $P = \\int_{\\mathcal{R}} p\\left(x\\right) dx $. 由于每个样本数据均独立，那么他们各自处于区域$\\mathcal{R}$的概率均为$P$ ,因此，区域$\\mathcal{R}$中刚好有$K$ 个数据的概率表示为;\n",
    "\n",
    "$$\n",
    " Bin\\left(K | N, P\\right) = \\frac{N!}{K!\\left(N-K\\right)!} P^K\\left(1-P\\right)^{1-K}\n",
    "$$\n",
    "\n",
    "我们可以从数据中估计，$E\\left[ K/N \\right] = P$, $var\\left[K/N\\right] = P\\left(1-P\\right)N$\n",
    "\n",
    "若假设，该区域$\\mathcal{R}$足够小，且在该区域内的概率密度函数$p\\left(x\\right)$ 为const,那么有：   \n",
    "$$\n",
    "P \\approx p\\left(x\\right)V  \\rightarrow   p\\left(x\\right) = \\frac{K}{NV}\n",
    "$$\n",
    "\n",
    "对于上述概率密度函数的估计，我们可以从两个方面入手 **1) 固定 $K$ , 从数据中获取$V$(K 最近邻方法); 2) 固定$V$, 从数据中获取$K$， （核函数方法）**. \n",
    "\n",
    "* 核函数方法\n",
    "\n",
    "我们首先固定 $V$ 为一个单位长的超方块（边长为1，多维的超正方体）， 然后来计算出位于该正方体内的点的个数， 定义如下核函数\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "k\\left(\\mathbf{u}\\right) =\n",
    "\\left\\{\\begin{matrix}\n",
    "&1, |u_i| \\leqslant 1/2, i = 1,...D;\n",
    "\\\\ \n",
    "&0, otherwise  \n",
    "\\end{matrix}\\right.                  \n",
    "\\end{split}\n",
    "$$\n",
    "因此，我们可以计算得到所有的位于该边长为h的cube V中的数据个数为：$K = \\sum_{n=1}^N k\\left(\\frac{x-x_n}{h}\\right) $\n",
    "\n",
    "因此估计得到概率密度函数为：\n",
    "$$\n",
    "p\\left(x\\right) = \\frac{1}{N}\\sum_{n=1}^N\\frac{1}{h^D}k\\left(\\frac{x-x_n}{h}\\right)\n",
    "$$\n",
    "由于上述核函数并不平滑，我们选择更为平滑的高斯函数，那么概率密度函数估计为：\n",
    "\n",
    "$$\n",
    "p\\left(x\\right) = \\frac{1}{N} \\sum_{n=1}^N\\frac{1}{\\left(2\\pi h^2\\right)^{1/2}}\\exp\\left[ -\\frac{\\|x-x_n\\|^2}{2h^2} \\right]\n",
    "$$\n",
    "![fig_2_25](2.5_fig_2_24.png)\n",
    "\n",
    "可以认为在上述核函数中的参数h扮演者重要的平滑角色，当h较小时，对于噪声比较敏感，而当h较大时有点过于平滑。为模型复杂度的重要参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.2 Nearst-neighbour methods\n",
    "\n",
    "**固定$K$, 求$V$ **来估算概率密度函数\n",
    "\n",
    "也就是说，我们在以数据$x_i$为圆心，已知扩张其区域范围直至包含有$k$个数据，求此时的区域容积来计算概率密度函数。\n",
    "![fig_2_26](2.5_fig_2_24.png)\n",
    "与前面核函数方法类似，我们这里也有模型复杂度的参数$k$, 一个合适的$k$也决定这模型的好坏。 \n",
    "\n",
    "\n",
    "* k近邻方法用于分类\n",
    "假设原始训练数据 第$\\mathcal{C}_k$类中刚好有$N_k$个观测数据，且$\\sum_k N_k = N$.现在我们需要对新的观测数据 $x$进行分类，首先，我们以$x$为中心，画一个圆(超球体)，使得该面积为$V$的圆内刚好有$K$个数据且来自$\\mathcal{C}_k$类数据$K_k$个， 计算此时圆的面积，得到\n",
    "* 似然概率：$p\\left(x| \\mathcal{C}_k\\right) = \\frac{K_k}{N_kV}$\n",
    "\n",
    "* 先验概率： $p\\left(\\mathcal{C}_k\\right) = \\frac{N_k}{N}$\n",
    "* 全局概率： $p\\left(x\\right) = \\frac{K}{NV}$\n",
    "\n",
    "* 后验概率： $p\\left(\\mathcal{C}_k |x\\right) = \\frac{K_k}{K}$\n",
    "\n",
    "要是按照最小错误率进行分类，那么分类时，应该选择最大后验概率的类别进行分类。\n",
    "\n",
    "\n",
    "\n",
    "** 总结**\n",
    "上述两种方法（核函数和最近邻），在学习过程中都需要将整个数据存储起来，计算复杂度非常大，有一些 树结构的存储方法可以解决计算复杂度的问题。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
